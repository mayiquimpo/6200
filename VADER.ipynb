{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00fc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e96cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mayi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mayi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mayi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e314200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "file_path = os.path.expanduser(\"~/Desktop/School/6200/Project/Reviews.csv\")  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07dd9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      " Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display column names\n",
    "print(\"Columns in the dataset:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00480cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n",
      "None\n",
      "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "count  568454.000000         568454.000000            568454.00000   \n",
      "mean   284227.500000              1.743817                 2.22881   \n",
      "std    164098.679298              7.636513                 8.28974   \n",
      "min         1.000000              0.000000                 0.00000   \n",
      "25%    142114.250000              0.000000                 0.00000   \n",
      "50%    284227.500000              0.000000                 1.00000   \n",
      "75%    426340.750000              2.000000                 2.00000   \n",
      "max    568454.000000            866.000000               923.00000   \n",
      "\n",
      "               Score          Time  \n",
      "count  568454.000000  5.684540e+05  \n",
      "mean        4.183199  1.296257e+09  \n",
      "std         1.310436  4.804331e+07  \n",
      "min         1.000000  9.393408e+08  \n",
      "25%         4.000000  1.271290e+09  \n",
      "50%         5.000000  1.311120e+09  \n",
      "75%         5.000000  1.332720e+09  \n",
      "max         5.000000  1.351210e+09  \n",
      "Id                         0\n",
      "ProductId                  0\n",
      "UserId                     0\n",
      "ProfileName               26\n",
      "HelpfulnessNumerator       0\n",
      "HelpfulnessDenominator     0\n",
      "Score                      0\n",
      "Time                       0\n",
      "Summary                   27\n",
      "Text                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get general info\n",
    "print(df.info())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad5af05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    568454.000000\n",
      "mean        436.222083\n",
      "std         445.339741\n",
      "min          12.000000\n",
      "25%         179.000000\n",
      "50%         302.000000\n",
      "75%         527.000000\n",
      "max       21409.000000\n",
      "Name: Text_Length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for text length\n",
    "df[\"Text_Length\"] = df[\"Text\"].astype(str).apply(len)\n",
    "\n",
    "# Display descriptive statistics for text length\n",
    "print(df[\"Text_Length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244d7ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165256    Having tried a couple of other brands of glute...\n",
      "231465    My cat loves these treats. If ever I can't fin...\n",
      "427827    A little less than I expected.  It tends to ha...\n",
      "433954    First there was Frosted Mini-Wheats, in origin...\n",
      "70260     and I want to congratulate the graphic artist ...\n",
      "49866     Please add more Pineapple flavor to your packa...\n",
      "551047    I absolutely love Yorkshire tea and am so glad...\n",
      "18983     I have such a hard time finding loose tea loca...\n",
      "138968    Previously, I've attempted a recipe with white...\n",
      "36352     I make pancakes or waffles every Saturday morn...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read a few random review samples\n",
    "print(df[\"Text\"].sample(10, random_state=45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6b5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83a62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Handle missing values\n",
    "    \n",
    "    # 1. Remove HTML tags using a regex pattern\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n",
    "\n",
    "    # 2. Replace URLs with a placeholder \"URL\"\n",
    "    text = re.sub(r'http[s]?://\\S+', 'URL', text)\n",
    "\n",
    "    # 3. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 4. Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # 5. Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # 6. Remove stopwords and lemmatize\n",
    "    cleaned_text = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    # 7. Replace multiple spaces with a single space\n",
    "    cleaned_text = \" \".join(cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67025b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the updated cleaning function to the Text column\n",
    "df[\"Cleaned_Text\"] = df[\"Text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd87b560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Text  \\\n",
      "300665  I have used this product before and found it t...   \n",
      "167485  The product arrived a bit later than expected ...   \n",
      "313460  I never eat this stuff, usually but Walmart ha...   \n",
      "7589    It's all natural, no artificial color, no weir...   \n",
      "48968   I've not actually used any other filter paper ...   \n",
      "\n",
      "                                             Cleaned_Text  \n",
      "300665  used product found best product jerk chicken c...  \n",
      "167485  product arrived bit later expected arrived goo...  \n",
      "313460  never eat stuff usually walmart sitting right ...  \n",
      "7589    natural artificial color weird ingredient also...  \n",
      "48968   ive actually used filter paper cant make compa...  \n"
     ]
    }
   ],
   "source": [
    "# Spot-checking\n",
    "spotcheck_sample = df[[\"Text\", \"Cleaned_Text\"]].sample(5, random_state=45)\n",
    "print(spotcheck_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35cc4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4afabd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  I have bought several of the Vitality canned d...   \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
      "2  This is a confection that has been around a fe...   \n",
      "3  If you are looking for the secret ingredient i...   \n",
      "4  Great taffy at a great price.  There was a wid...   \n",
      "\n",
      "                                        Cleaned_Text  \\\n",
      "0  bought several vitality canned dog food produc...   \n",
      "1  product arrived labeled jumbo salted peanutsth...   \n",
      "2  confection around century light pillowy citrus...   \n",
      "3  looking secret ingredient robitussin believe f...   \n",
      "4  great taffy great price wide assortment yummy ...   \n",
      "\n",
      "                                              Tokens  Word_Count  \\\n",
      "0  [bought, several, vitality, canned, dog, food,...        23.0   \n",
      "1  [product, arrived, labeled, jumbo, salted, pea...        18.0   \n",
      "2  [confection, around, century, light, pillowy, ...        40.0   \n",
      "3  [looking, secret, ingredient, robitussin, beli...        18.0   \n",
      "4  [great, taffy, great, price, wide, assortment,...        13.0   \n",
      "\n",
      "   Unique_Word_Count  Avg_Word_Length  Sentiment_Score  \n",
      "0               20.0         6.043478           0.9413  \n",
      "1               16.0         6.555556          -0.1027  \n",
      "2               37.0         5.975000           0.8532  \n",
      "3               18.0         6.166667           0.4404  \n",
      "4               10.0         5.461538           0.9468  \n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Cleaned_Text once and store it in a new column 'Tokens'\n",
    "df['Tokens'] = df['Cleaned_Text'].apply(word_tokenize)\n",
    "\n",
    "# Apply Feature Engineering on the pre-tokenized text\n",
    "def extract_features_from_tokens(tokens):\n",
    "    word_count = len(tokens)\n",
    "    unique_word_count = len(set(tokens))\n",
    "    avg_word_length = sum(len(word) for word in tokens) / word_count if word_count else 0\n",
    "\n",
    "    # Sentiment analysis with VADER\n",
    "    sentiment = analyzer.polarity_scores(\" \".join(tokens))  # VADER expects a string, not tokens\n",
    "\n",
    "    return [word_count, unique_word_count, avg_word_length, sentiment['compound']]\n",
    "\n",
    "# Now apply the feature extraction on the 'Tokens' column (pre-tokenized)\n",
    "df[['Word_Count', 'Unique_Word_Count', 'Avg_Word_Length', 'Sentiment_Score']] = df['Tokens'].apply(\n",
    "    lambda x: pd.Series(extract_features_from_tokens(x)))\n",
    "\n",
    "# Spot-check the results\n",
    "print(df[['Text', 'Cleaned_Text', 'Tokens', 'Word_Count', 'Unique_Word_Count', 'Avg_Word_Length', 'Sentiment_Score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb58b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Cleaned_Text  Sentiment_Score  \\\n",
      "0  bought several vitality canned dog food produc...           0.9413   \n",
      "1  product arrived labeled jumbo salted peanutsth...          -0.1027   \n",
      "2  confection around century light pillowy citrus...           0.8532   \n",
      "3  looking secret ingredient robitussin believe f...           0.4404   \n",
      "4  great taffy great price wide assortment yummy ...           0.9468   \n",
      "\n",
      "  Sentiment_Label  \n",
      "0        Positive  \n",
      "1        Negative  \n",
      "2        Positive  \n",
      "3        Positive  \n",
      "4        Positive  \n"
     ]
    }
   ],
   "source": [
    "def classify_sentiment(sentiment_score):\n",
    "    if sentiment_score > 0.1:\n",
    "        return \"Positive\"\n",
    "    elif sentiment_score < -0.1:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply sentiment classification based on VADER sentiment score\n",
    "df['Sentiment_Label'] = df['Sentiment_Score'].apply(classify_sentiment)\n",
    "\n",
    "# Show some of the classified sentiments\n",
    "print(df[['Cleaned_Text', 'Sentiment_Score', 'Sentiment_Label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71ca08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 100 random rows\n",
    "random_sample = df.sample(100, random_state=45)\n",
    "\n",
    "# Extract sentiment predictions from VADER\n",
    "random_sample['VADER_Sentiment'] = random_sample['Sentiment_Score'].apply(\n",
    "    lambda score: 'positive' if score > 0 else 'negative' if score < 0 else 'neutral'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0613884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Text VADER_Sentiment\n",
      "300665  I have used this product before and found it t...        negative\n",
      "167485  The product arrived a bit later than expected ...        positive\n",
      "76005   The flavor in these is intense and wonderful. ...        positive\n",
      "146696  My first cup, I said \"wow\" -- Henry's Blend is...        positive\n",
      "203398  This is a highly unusual tea -- real licorice ...        positive\n"
     ]
    }
   ],
   "source": [
    "# Spot-check several examples\n",
    "spotcheck_sample = random_sample[['Text', 'VADER_Sentiment']].sample(5, random_state=45)\n",
    "\n",
    "print(spotcheck_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1762082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text: My son had a little trouble on occasion with constipation and when he did, this would be our go to meal. The prunes always seemed to help, and he loves the taste.\n",
      "VADER Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Review Text: This baby food has very simple ingredients: no sugar added, no preservatives (lemon juice only), no coloring. It is mostly all pear however. There is very little iron (2%), that I though it should have had from spinach, and virtually no protein - again, I though broccoli would add protein to this mix. It does have 70% of vitamin C however. Taste good: not over the top sweet from the pear and not over the top tart from the lemon juice.  I really wish it would have more greens in it though.\n",
      "VADER Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Review Text: As a vet tech interested in pet nutrition Royal Canin is one of the best. My cat really likes this food and it seems to be agreeing with her. Concentrated nutrition and easy litter box clean up is a plus. It is a little pricey, but when it comes to cat and dog food you get what you pay for.\n",
      "VADER Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Review Text: These are pretty nice brushes to clean the automatic cat water bowls we brought.  Versatile set of brushes<br />that can reach almost crack and crevice.  Really like them a lot!\n",
      "VADER Sentiment: positive\n",
      "--------------------------------------------------\n",
      "Review Text: I discovered this granola at Fairway and could not find it anywhere else. I love it so much that I ordered a large quantity of it. It's amazing granola -simple, light and tasty. Better than any other brand I've ever tried.\n",
      "VADER Sentiment: positive\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To manually review the sentiment, you can check the first few examples\n",
    "for idx, row in spotcheck_sample.iterrows():\n",
    "    print(f\"Review Text: {row['Text']}\")\n",
    "    print(f\"VADER Sentiment: {row['VADER_Sentiment']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
