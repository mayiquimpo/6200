{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91af00fa-f4b2-4b19-b1fe-9a01e2963117",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6888d093-d9a2-442a-8ec8-b6964ed318b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "import json\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3902eede-4fd6-4658-994f-5d3ae2b49763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  Thousands of demonstrators have marched throug...   \n",
       "1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n",
       "2  Sentence: 3  They marched from the Houses of Parliament to ...   \n",
       "3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n",
       "4  Sentence: 5  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
       "1  ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n",
       "2  ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n",
       "3  ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...   \n",
       "4  ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ner.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9eaf393-ae64-4635-ba53-9f97ffe3e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Tag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717e09fa-71f2-4754-8224-404d9415db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  Thousands of demonstrators have marched throug...   \n",
       "1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n",
       "2  Sentence: 3  They marched from the Houses of Parliament to ...   \n",
       "3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n",
       "4  Sentence: 5  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 POS  \n",
       "0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...  \n",
       "1  ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...  \n",
       "2  ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...  \n",
       "3  ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...  \n",
       "4  ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcce4890-3fab-4b01-8901-51b4495568be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #\n",
       "Sentence: 1        1\n",
       "Sentence: 31978    1\n",
       "Sentence: 31969    1\n",
       "Sentence: 31970    1\n",
       "Sentence: 31971    1\n",
       "                  ..\n",
       "Sentence: 15989    1\n",
       "Sentence: 15990    1\n",
       "Sentence: 15991    1\n",
       "Sentence: 15992    1\n",
       "Sentence: 47959    1\n",
       "Name: count, Length: 47959, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentence #'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628b714d-62a1-4b18-b1f1-84cf9f5fbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.head(210).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015d164-7b24-4540-b3b9-e0215d26c2ce",
   "metadata": {},
   "source": [
    "## SpaCy en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5c5db1-458a-4f67-8e34-8aef61680efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get Doccano-style entities\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_spacy_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [[ent.start_char, ent.end_char, ent.label_] for ent in doc.ents]\n",
    "\n",
    "# Create Doccano-ready columns\n",
    "sample_df[\"text\"] = sample_df[\"Sentence\"]\n",
    "sample_df[\"label\"] = sample_df[\"Sentence\"].apply(get_spacy_entities)\n",
    "\n",
    "# Only keep relevant columns\n",
    "spacy_df = sample_df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28468071-84f0-4459-9638-99233a2c7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_export(df, output_path=\"spacy_ner.jsonl\"):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            text = row[\"text\"]\n",
    "            labels = row[\"label\"] if isinstance(row[\"label\"], list) else []\n",
    "            json.dump({\"text\": text, \"label\": labels}, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "# Usage\n",
    "spacy_export(spacy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9bf37-e974-43d7-9378-18b7385c6c51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# STOP HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33569914-e3dd-4310-8f34-9449c3ea9c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve the entity label names from the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m labels \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Function to convert numerical NER tags into human-readable labels\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_ner_tags\u001b[39m(example):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieve the entity label names from the dataset\n",
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "# Function to convert numerical NER tags into human-readable labels\n",
    "def decode_ner_tags(example):\n",
    "    example[\"ner_labels\"] = [labels[tag] for tag in example[\"ner_tags\"]]\n",
    "    return example\n",
    "\n",
    "# Apply the function to all data splits\n",
    "dataset = dataset.map(decode_ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5544208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entity Types in the Dataset:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16a190-0b23-49c6-96da-37b01738f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "df = train_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34189ffd-5060-43f3-b390-72ed0ec0ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique document IDs\n",
    "num_documents = df[\"doc_id\"].nunique()\n",
    "print(f\"Number of unique documents: {num_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702860e-6d96-44c9-8881-1bbe47e614b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy import displacy\n",
    "\n",
    "# Load a blank spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Function to visualize Named Entities\n",
    "def visualize_ner(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    labels = example[\"ner_labels\"]\n",
    "    start_chars = example[\"start_char\"]\n",
    "    end_chars = example[\"end_char\"]\n",
    "\n",
    "    # Convert entity positions into spaCy's expected format\n",
    "    ents = []\n",
    "    for start, end, label in zip(start_chars, end_chars, labels):\n",
    "        if label != \"O\":  # Ignore \"O\" (Outside) labels\n",
    "            ents.append(nlp.make_doc(example[\"sentence\"]).char_span(start, end, label=label))\n",
    "\n",
    "    # Create a spaCy Doc object\n",
    "    doc = nlp.make_doc(example[\"sentence\"])\n",
    "\n",
    "    # Assign named entities (filter out None values)\n",
    "    doc.ents = [ent for ent in ents if ent is not None]\n",
    "\n",
    "    # Render visualization in Jupyter Notebook\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "# Display the first example with highlighted named entities\n",
    "visualize_ner(dataset[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the pretrained model and display structured results\n",
    "def evaluate_ner_predictions(example):\n",
    "    text = example[\"sentence\"]\n",
    "    doc = nlp_core(text)  # Use pretrained model\n",
    "    predictions = [(ent.text, ent.label_) for ent in doc.ents]  # Extract model-predicted entities\n",
    "\n",
    "    # Compare with dataset labels\n",
    "    expected_entities = list(zip(example[\"tokens\"], example[\"ner_labels\"]))\n",
    "\n",
    "    # Convert to DataFrame for better readability\n",
    "    df_results = pd.DataFrame(predictions, columns=[\"Text Span\", \"Model Prediction\"])\n",
    "    df_expected = pd.DataFrame(expected_entities, columns=[\"Text Span\", \"Expected Label\"])\n",
    "\n",
    "    # Merge for side-by-side comparison\n",
    "    results_df = df_results.merge(df_expected, on=\"Text Span\", how=\"outer\").fillna(\"N/A\")\n",
    "\n",
    "    print(results_df)\n",
    "\n",
    "# Test on a sample\n",
    "evaluate_ner_predictions(dataset[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d467824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process text and extract entities\n",
    "def get_entities_from_text(text):\n",
    "    # Process the text with spaCy model\n",
    "    doc = nlp(text)\n",
    "    # Return a list of tuples with entity text and label\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Manually annotated sentences\n",
    "manual_annotations = [\n",
    "    (\"2011-05-04T07:24:07Z -- http://www.bloomberg.com/news/2011-05-04/bbva-is-said-to-announce-falling-profit-on-thursday.html\", []),\n",
    "    (\"Net income probably declined to 1.08 billion euros ($1.6 billion) from 1.24 billion euros a year earlier, according to the average estimate in a Bloomberg survey of six analysts.\", [(\"Net income\", \"MONEY\"), (\"euros\", \"MONEY\"), (\"Bloomberg\", \"ORG\"), (\"six analysts\", \"ORG\")]),\n",
    "    (\"The Bilbao, Spain-based lender is scheduled to report first-quarter results tomorrow before the stock market opens in Spain.\", [(\"Bilbao\", \"GPE\"), (\"Spain\", \"GPE\")]),\n",
    "    (\"Spanish banks have been hurt by weakening credit demand and souring loans in a domestic economy that’s still struggling to emerge from recession.\", [(\"Spanish banks\", \"ORG\")]),\n",
    "    (\"BBVA, led by Chairman Francisco Gonzalez, completed its $5.8 billion purchase of a 24.9 percent stake in Turkiye Garanti Bankasi AS (GARAN) in March as it expands outside Spain, adding Turkey to other emerging markets such as Mexico.\", [(\"BBVA\", \"ORG\"), (\"Francisco Gonzalez\", \"PERSON\"), (\"$5.8 billion\", \"MONEY\"), (\"Turkiye Garanti Bankasi AS (GARAN)\", \"ORG\"), (\"March\", \"TIME\"), (\"Spain\", \"GPE\"), (\"Turkey\", \"GPE\"), (\"Mexico\", \"GPE\")]),\n",
    "    (\"“The news from Spain won’t be good, but there probably won’t be nasty surprises while Mexico is showing interesting growth,” said Pablo Garcia, head of equities at Oddo Sociedad de Valores in Madrid.\", [(\"Spain\", \"GPE\"), (\"Mexico\", \"GPE\"), (\"Pablo Garcia\", \"PERSON\"), (\"Oddo Sociedad de Valores\", \"ORG\"), (\"Madrid\", \"GPE\")]),\n",
    "    (\"“All the big Spanish companies, and that includes BBVA, are at pains now to show that Spain is a diminishing part of their business.” BBVA shares have gained 14 percent this year, compared with a 2.9 percent advance in the 48-member Bloomberg Europe Banks and Financial Services Index.\", [(\"Spanish companies\", \"ORG\"), (\"BBVA\", \"ORG\"), (\"Spain\", \"GPE\"), (\"BBVA\", \"ORG\"), (\"Bloomberg\", \"ORG\"), (\"Europe\", \"GPE\")]),\n",
    "    (\"Banco Santander SA (SAN), Spain’s largest bank, which on April 28 reported a 5 percent drop in first-quarter profit, has risen 5.3 percent in 2011.\", [(\"Banco Santander SA (SAN)\", \"ORG\"), (\"Spain\", \"GPE\"), (\"April 28\", \"TIME\"), (\"2011\", \"TIME\")]),\n",
    "    (\"Mexican Gains Profit from BBVA’s Spain-dominated Iberian business may have dropped 33 percent from a year earlier to 394 million euros, according to estimates by Banco BPI SA (BPI) analyst Carlos Joaquim Peixoto.\", [(\"BBVA\", \"ORG\"), (\"Spain\", \"GPE\"), (\"Iberian business\", \"ORG\"), (\"Banco BPI SA (BPI)\", \"ORG\"), (\"Carlos Joaquim Peixoto\", \"PERSON\")]),\n",
    "    (\"Spain and Portugal together accounted for 45 percent of group profit in 2010.\", [(\"Spain\", \"GPE\"), (\"Portugal\", \"GPE\"), (\"2010\", \"TIME\")])\n",
    "]\n",
    "\n",
    "# Retrieve 10 random samples from the dataset\n",
    "sample_data = dataset[\"train\"].select(range(10))\n",
    "\n",
    "# Store annotations and predictions\n",
    "annotations = []\n",
    "\n",
    "for i, example in enumerate(sample_data):\n",
    "    text = example[\"sentence\"]\n",
    "    \n",
    "    # Get the manual annotations for the text\n",
    "    manual_annotation = manual_annotations[i][1]\n",
    "    \n",
    "    # Get the model's predictions\n",
    "    model_prediction = get_entities_from_text(text)\n",
    "    \n",
    "    # Store both manual annotations and model predictions\n",
    "    annotations.append({\n",
    "        \"text\": text,\n",
    "        \"manual_label\": manual_annotation,\n",
    "        \"model_prediction\": model_prediction\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "df_manual = pd.DataFrame(annotations)\n",
    "print(df_manual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
